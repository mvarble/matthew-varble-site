
notion of observing $X$ takes a value $x \in S$, any subsequent calculation $f(x)$ from $f: S \rightarrow \bbR^d$ I make can be built into the probability model as a composition $f(X) = f \circ X: \Omega \rightarrow \bbR^d$.

Fortunately for us, we have a way of modeling information in a probability space.
In this post, I intend to show how we model information and optimal inference within a probability space.
This is done from a purely abstract point of view.

> Provided a probability space $(\Omega, \Sigma, \rmP)$ and a measurable map $X: \Omega \rightarrow S$ to a measure space $(S, \calS)$, can we somehow characterize $f(X)$ which best approximate some value $Y: \Omega \rightarrow \bbR^n$ with this knowledge?

It is well known that when $X$ takes values in some $\bbR^m$ and $(X, Y)$ has a joint density $p$ with respect to the Lebesgue measure on $\bbR^{m+n}$, we answer this problem by defining a conditional density $p(\cdot|x)$ for $Y$ on the observation $X = x$,

<span>{ String.raw`
  $$ p(y | x) = \frac{p(x,y)}{\int_{\bbR^n} p(x,z) {\rm d}z}, $$
`}</span>

and subsequently take the following conditional expectation.

<span>{ String.raw`
  $$ \rmE\big( Y | X = x \big) = \frac{\int_{\bbR^m} y p(x, y) {\rm d}y}{\int_{\bbR^n} p(x, z) {\rm d}z} $$
`}</span>

<p>{ String.raw`
  However, when $S$ is a far more complicated space, like a set of paths $\bbR^{[0,t]}$, we do not have a Lebesgue measure over which we have nice density functions.
  The above definitions do not allow us to model a problem like below.
`}</p>

<div style={{ display: 'flex', marginBottom: '1em' }}>
  <div className="box" style={{ margin: '0 auto', maxWidth: '512px' }}>
    <img src={ ratPath } alt="complicated-rat-path" style={{ margin: '1em auto', display: 'block' }}/>
    <div style={{ marginTop: '1em' }}>{ String.raw`
        A rat will walk a random path in $\bbR^2$, denoted by the following measurable function.
        $$ W: \Omega \rightarrow (\bbR^2)^{[0,T]} $$
        After observing that his path $X = W|_{[0,t]}$ up to some time $t < T$ takes value $x \in \bbR^{[0,t]}$, how do I infer his position $Y = W(T)$ at a future time $T$?
        $$ \rmE\big( Y | X = x \big) = ? $$
      `}
    </div>
  </div>
</div>

For such problems, we must use a generalized notion of *conditional expectation* which is far more difficult to comprehend than that from a conditional density $p(\cdot|x)$. 
I personally spent a lot of time playing with this definition, and only after many toy examples did I finally understand why it is defined as it is.
I really hope this post, though somewhat long, will help someone spend less time than I did!

## Conditional expectation

Before we dive in, let's denote the set of measurable functions between a pair measurable spaces $(\Omega, \Sigma)$, $(\Omega', \Sigma')$ like so.

<span>{ String.raw`
  $$ \Sigma/\Sigma' = \Big\{ X: \Omega \rightarrow \Omega' : X^{-1}B \in \Sigma \text{ for all } B \in \Sigma' \Big\} $$
`}</span>

Let us also denote $\calR^d$ as the Borel space on $\bbR^d$ induced by the Euclidean topology and $\calR = \calR^1$ and the $L^p$ class as such.

<span>{ String.raw`
  $$ L^p(\Omega, \Sigma, \rmP) = \Big\{ Y \in \Sigma/\calR^d : \rmE(|Y|^p) < \infty \Big\} $$
`}</span>

> **Definition.**
> Let $(\Omega, \Sigma, \rmP)$ be a probability space.
> Provided a $\sigma$-algebra $\Sigma'$ on $\Omega$ with $\Sigma' \subseteq \Sigma$ and scalar-valued $Y \in L^1(\Omega, \Sigma, \rmP)$, we define a $(\rmP, \Sigma')$-conditional expectation $\rmE(Y|\Sigma')$ as any function which satisfies the following.
> - $\rmE(Y|\Sigma') \in \Sigma'/\calR$
> - For all nonnegative bounded $Z \in \Sigma'/\calR$,
> $$ \rmE\big( \rmE(Y|\Sigma') \cdot Z \big) = \rmE\big( Y \cdot Z \big). $$

Note that the definition says *a* conditional expectation, not *the* conditional expectation.
It turns out that conditional expectations $\rmE(Y|\Sigma')$ always exist, and we denote them with this fixed notation because two distinct conditional expectations will be equal $\rmP$-almost-everywhere.
For this reason, we will often abusingly say *the* conditional expectation $\rmE(Y|\Sigma')$ when refering to a fixed version of one.

Now we may reflect on the confusing parts of this definition.

- We are taking a conditional expectation with respect to a $\sigma$-algebra $\Sigma'$. We would instead like to have a conditional expectation depend on $X \in \Sigma/\calS$ for some measurable space $(S, \calS)$.
- The resulting object $\rmE(Y|\Sigma')$ is a function $\Omega \rightarrow \bbR$. We would instead like a function $\rmE(Y|X=\cdot): S \rightarrow \bbR$.
                                                                                                                                    
These issues are immediately addressed as soon as we correspond a natural $\sigma$-algebra for a function $X \in \Sigma/\calS$.

## $\sigma(X,\calS)$

<blockquote>
  <strong>Definition.</strong> Let $(S, \calS)$ be a measurable space and $X: \Omega \rightarrow S$.
  Define $\sigma(X, \calS)$ as the following subset of $2^\Omega$.
  { String.raw`
    $$ \sigma(X, \calS) = \Big\{ X^{-1}B : B \in \calS \Big\} $$
  `}
</blockquote>

The notation $\sigma(X, \calS)$ suggests a $\sigma$-algebra at play, and the keen eye should see that the definition of measurability of $X$ is in plain sight.
This intuition is plainly stated in the following result.

<blockquote>
  <strong>Result.</strong> The set $\sigma(X, \calS)$ is a $\sigma$-algebra on $\Omega$.
  Furthermore, it is the smallest $\sigma$-algebra $\Sigma$ such that $X \in \Sigma/\calS$.
  <Proof withBlock={ false } style={{ margin: '1em 0' }}>
    The $\sigma$-algebra property is immediately inherited from $\calS$.
    <ul>
      <li>{ String.raw`
        Because $\calS$ is a $\sigma$-algebra, $S \in \calS$, which shows 
        $$\Omega = X^{-1}S \in \sigma(X, \calS).$$
      `}</li>
      <li>{ String.raw`
        Let $A \in \sigma(X, \calS)$.
        By definition, there is some $B \in \calS$ such that $A = X^{-1}B$.
        Because $\calS$ is a $\sigma$-algebra, $S \setminus B \in \calS$, so 
        $$\Omega \setminus A = X^{-1}(S \setminus B) \in \sigma(X, \calS).$$
      `}</li>
      <li>{ String.raw`
        Provided some countable family $\{A_n\}_{n\geq 1} \subseteq \sigma(X, \calS)$, each member $A_n = X^{-1}B_n$ for some $B_n \in \calS$.
        Because $\calS$ is a $\sigma$-algebra, 
        $$ \bigcup_{n\geq 1} B_n \in \calS $$
        which shows us
        $$ \bigcup_{n\geq 1} A_n = X^{-1}\bigcup_{n\geq 1} B_n \in \sigma(X, \calS). $$
      `}</li>
    </ul>
    { String.raw`
      The minimality property is also immediate.
      Let $\Sigma$ be a $\sigma$-algebra on $\Omega$ with $X \in \Sigma/\calS$.
      Fix $A \in \sigma(X, \calS)$ and note that some $B \in \calS$ is such that $A = X^{-1}B$.
      Now $A = X^{-1}B \in \Sigma$, whence $X \in \Sigma/\calS$.
    `}
  </Proof>
</blockquote>

A less obvious pattern to find is the nature of random variables $Y \in \sigma(X, \calS)/\calR$.
This will be the key to understanding the definition of conditional expectation above.
Before we state any results or proofs, let's consider a simple example.

## Simple example

<p>
  { String.raw`
    Suppose I buy a carton of milk which I intend to use to make yogurt.
    Some amount of days $x \in \{ 1, \ldots, 7 \}$ from now, I will cultivate the yogurt, a process which takes $w \in \{1, 2\}$ days.
  ` }
  <em>Immediately</em> after the yogurt is ready, I share the rewards with my brothers.
</p>

<div style={{ display: 'flex', marginBottom: '1em' }}>
  <div className="box" style={{ margin: '0 auto' }}>
    <img alt="rats eating yogurt!" src={ yogurt }/>
    <div style={{ textAlign: 'center', marginTop: '1em' }}> They love it! </div>
  </div>
</div>

<p>{ String.raw`
  Let's model this with measurable spaces and explore the $\sigma$-algebras.
  We are going to specify all the information of the measurable spaces to see how the $\sigma$-algebras relate to full detail.
  For a provided $\sigma$-algebra $\calS$, and $A \subseteq \calS$, let's denote a relative $\sigma$-algebra on $A$.
  $$ \calS_A = \big\{ A \cap B : B \in \calS \big\} $$
  Now, denote the following.
  $$
    \begin{aligned}
      1\:k = \{1, \ldots, k \} \\
      \Omega = 1\:7 \times 1\:2 \\
      \Sigma = 2^\Omega \\
      X: \Omega \rightarrow 1\:7, & \qquad X(x, w) = x, &\quad (x, w) \in \Omega = 1\:7\times 1\:2 \\
      W: \Omega \rightarrow 1\:2, & \qquad W(x, w) = w, &\quad (x, w) \in \Omega = 1\:7\times 1\:2
    \end{aligned}
  $$
  Listing out $\sigma(X, \calR_{1:7})$ is actually quite easy.
  Note first that $\calR_{1:7}$ is just the powerset of $1\:7$.
  $$ \calR_{1:7} = \big\{ A \cap \{1, \ldots, 7\} : A \in \calR \big\} = \big\{ \emptyset, \{1\}, \ldots, \{7\}, \{1, 2\}, \ldots, \{1, \ldots, 7\} \big\} $$
  Taking the preimages of these sets via $X$ then allows us to list $\sigma(X, \calR_{1:7})$ as well.
  $$ \sigma(X, \calR_{1:7}) = \Big\{ \emptyset, X^{-1}\{1\}, \ldots, X^{-1}\{7\}, X^{-1}\{1, 2\}, \ldots, X^{-1}\{1, \ldots, 7\} \Big\} $$
  The atom preimages $X^{-1}\{j\}$ are of highest interest, as every other nonempty set in $\sigma(X, \calR_{1:7})$ is a union of them.
  $$ X^{-1}\{j\} = \big\{ (j, 1), (j, 2) \big\} $$
`}</p>

### Not measurable from $\sigma(X, \calR_{1:7})$

<p>{ String.raw`
  Let's now see that $W \not\in \sigma(X, \calR_{1:7}) / \calR_{1:2}$.
  Observe that we may list out $W^{-1}\{1\}$.
  $$ W^{-1}\{1\} = \big\{ (1, 1), \ldots, (7, 1) \big\} $$
  Every nonempty element of $\sigma(X, \calR_{1:2})$ contains an element $(j, 2)$, so $W^{-1}\{1\} \not\in \sigma(X, \calR_{1:7})$.
  Because $\{1\} \in \calR_{1:2}$, this is sufficient in concluding $W \not\in \sigma(X, \calR_{1:7}) / \calR_{1:2}$.
`}</p>

### Measurable from $\sigma(X, \calR_{1:7})$

<p>{ String.raw`
  On the contrary, suppose we have some real-valued inference $f(X)$; that is $f: 1\:7 \rightarrow \bbR$ is a calculation with measurability $f \in \calR_{1:7}/\calR$ we intend to make to an observation of $X$.
  $$ f(X) = f\circ X: \Omega \rightarrow \bbR $$
  By composition of measurable maps and $X \in \sigma(X, \calR_{1:7})/\calR_{1:7}$, we immediately get $f(X) \in \sigma(X, \calR_{1:7})/\calR$.
  Indeed, any $A \in \calR$ will be such that $f^{-1}A \subseteq \calR_{1:7}$, and so
  $$ f(X)^{-1}A = X^{-1}f^{-1}A \in \sigma(X, \calR_{1:7}). $$
`}</p>


<p>{ String.raw`
  Not so coincidentally, any other function $Z \in \sigma(X, \calR_{1:7})/\calR$ will also be an inference $Z = f(X)$ for $f \in \calR_{1:7}/\calR$.
`}</p>

<Proof>
  <span>{ String.raw`
    Let $Z \in \sigma(X, \calR_{1:7})/\calR$ and select $\omega, \omega' \in \Omega$ with $X(\omega) = X(\omega')$.
    Now, by virtue of $\{Z(\omega)\} \in \calR$ and $Z \in \sigma(X, \calR_{1:7})/\calR$, we have
    $$ Z^{-1}\{Z(\omega)\} \in \sigma(X, \calR_{1:7}) $$
    and so definition of $\sigma(X, \calR_{1:7})$ provides the existence of $B \in \calR_{1:7}$ such that
    $$ Z^{-1}\{Z(\omega)\} = X^{-1}B. $$
    Surely, $\omega \in Z^{-1}\{Z(\omega)\}$, so $\omega \in X^{-1}B$, which means $X(\omega) \in B$.
    This must also mean that $X^{-1}(\omega') \in B$ by equality $X(\omega) = X(\omega')$, and so
    $$ \omega' \in X^{-1}B = Z^{-1}\{Z(\omega)\}. $$
    We now have $Z(\omega) = Z(\omega')$.
  `}</span>
  <p style={{ marginTop: '1em' }}>{ String.raw`
    We have now shown $Z(\omega) = Z(\omega')$ whenever $X(\omega) = X(\omega')$.
    Because $X$ is surjective, this makes $f: 1\:7 \rightarrow \bbR$ below well-defined.
    $$ f(x) = Z(\omega), \text{ where } X(\omega) = x $$
    Further, $f \in \calR_{1:7}/\calR$, simply because $\calR_{1:7} = 2^{1:7}$.
  `}</p>
</Proof>

### Takeaway

<p>{ String.raw`
  Provided observations $X = x \in S$, we make subsequent calculations $f(x) \in \bbR$ as inferences for a variety of problems.
  In the probability model, our choice of inference is modeled as composing measurable function $f \in \calS/\calR$ and considering the random variable $f(X)$ distributing from all the possible outcomes of $X$.
  If we want to optimize some cost of the following form:
  $$ \inf_{f \in \calS/\calR} \operatorname{Cost}(f(X)), $$
  the previous results tell us that this is the same as the following representation.
  $$ \inf_{f \in \calS/\calR} \operatorname{Cost}(f(X)) = \inf_{Z \in \sigma(X, \calS)/\calR} \operatorname{Cost}(Z) $$
`}</p>
